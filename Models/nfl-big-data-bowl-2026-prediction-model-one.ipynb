{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":13825858,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================================================================\n# NFL BIG DATA BOWL 2026 - IMPROVED SOLUTION\n# Enhanced player movement prediction with advanced temporal features and physics\n# ================================================================================\n\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport gc\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import gaussian_filter1d\n\n# Machine Learning\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GroupKFold\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\n# Deep Learning\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\nwarnings.filterwarnings('ignore')\n\n# ================================================================================\n# GPU REQUIREMENTS CHECK\n# ================================================================================\n\ndef check_gpu_requirements():\n    \"\"\"Check if all required GPU libraries are available\"\"\"\n    gpu_available = torch.cuda.is_available()\n    \n    if gpu_available:\n        print(\"‚úÖ CUDA is available\")\n        try:\n            import xgboost\n            print(\"‚úÖ XGBoost GPU support available\")\n        except ImportError:\n            print(\"‚ö†Ô∏è  XGBoost not found - install with: pip install xgboost\")\n        \n        try:\n            import lightgbm\n            print(\"‚úÖ LightGBM GPU support available\")\n        except ImportError:\n            print(\"‚ö†Ô∏è  LightGBM not found - install with: pip install lightgbm\")\n        \n        try:\n            import catboost\n            print(\"‚úÖ CatBoost GPU support available\")\n        except ImportError:\n            print(\"‚ö†Ô∏è  CatBoost not found - install with: pip install catboost\")\n    else:\n        print(\"‚ö†Ô∏è  CUDA not available - will use CPU for all models\")\n    \n    return gpu_available\n\n# ================================================================================\n# CONFIGURATION\n# ================================================================================\n\nclass Config:\n    DATA_DIR = Path(\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\")\n    SEEDS = [42, 123, 2024]  # Multiple seeds for ensemble\n    FIELD_X_MIN, FIELD_X_MAX = 0.0, 120.0\n    FIELD_Y_MIN, FIELD_Y_MAX = 0.0, 53.3\n    MAX_SPEED = 12.0\n    N_FOLDS = 5\n    NN_BATCH_SIZE = 2048\n    NN_EPOCHS = 30\n    NN_LEARNING_RATE = 0.001\n    \n    # GPU Configuration\n    USE_GPU = True\n    GPU_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n    GPU_COUNT = torch.cuda.device_count() if torch.cuda.is_available() else 0\n    \n    @classmethod\n    def print_gpu_info(cls):\n        \"\"\"Print GPU information and availability\"\"\"\n        print(\"=\"*60)\n        print(\"GPU CONFIGURATION\")\n        print(\"=\"*60)\n        print(f\"CUDA Available: {torch.cuda.is_available()}\")\n        print(f\"GPU Device: {cls.GPU_DEVICE}\")\n        print(f\"GPU Count: {cls.GPU_COUNT}\")\n        \n        if torch.cuda.is_available():\n            for i in range(cls.GPU_COUNT):\n                gpu_name = torch.cuda.get_device_name(i)\n                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3\n                print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n        else:\n            print(\"No GPU available - using CPU\")\n        print(\"=\"*60)\n    \n    @classmethod\n    def cleanup_gpu_memory(cls):\n        \"\"\"Clean up GPU memory\"\"\"\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            torch.cuda.synchronize()\n        gc.collect()\n\n# ================================================================================\n# ENHANCED NFL PLAYER MOVEMENT PREDICTOR\n# ================================================================================\n\nclass EnhancedNFLPlayerMovementPredictor:\n    \"\"\"Enhanced NFL Player Movement Prediction with advanced temporal features\"\"\"\n    \n    def __init__(self, data_dir, seed=42):\n        self.data_dir = Path(data_dir)\n        self.seed = seed\n        self.weeks = list(range(1, 18))\n        self.models_dx = {}\n        self.models_dy = {}\n        self.scalers = {}\n        self.label_encoders = {}\n        self.nn_models_dx = []\n        self.nn_models_dy = []\n        \n    def load_and_combine_datasets(self):\n        \"\"\"Load and combine weekly training data with progress tracking\"\"\"\n        print(\"Loading datasets...\")\n        \n        input_paths = [self.data_dir / f\"train/input_2023_w{w:02d}.csv\" for w in self.weeks]\n        output_paths = [self.data_dir / f\"train/output_2023_w{w:02d}.csv\" for w in self.weeks]\n        \n        # Filter existing files\n        input_paths = [p for p in input_paths if p.exists()]\n        output_paths = [p for p in output_paths if p.exists()]\n        \n        print(f\"Found {len(input_paths)} weeks of training data\")\n        \n        train_input = self._load_multiple_csv_files(input_paths)\n        train_output = self._load_multiple_csv_files(output_paths)\n        \n        test_input = pd.read_csv(self.data_dir / \"test_input.csv\")\n        test_template = pd.read_csv(self.data_dir / \"test.csv\")\n        \n        print(f\"Loaded {len(train_input):,} input records, {len(train_output):,} output records\")\n        \n        return train_input, train_output, test_input, test_template\n    \n    def _load_multiple_csv_files(self, file_paths):\n        \"\"\"Load and concatenate multiple CSV files with progress tracking\"\"\"\n        data_frames = []\n        for p in tqdm(file_paths, desc=\"Loading files\"):\n            data_frames.append(pd.read_csv(p))\n        return pd.concat(data_frames, ignore_index=True)\n    \n    def _convert_height_to_inches(self, height_str):\n        \"\"\"Convert height from 'ft-in' format to total inches\"\"\"\n        if not isinstance(height_str, str) or '-' not in height_str:\n            return 70  # Default height\n        try:\n            feet, inches = map(int, height_str.split('-'))\n            return feet * 12 + inches\n        except (ValueError, AttributeError):\n            return 70\n    \n    def _extract_temporal_features(self, tracking_data):\n        \"\"\"Extract comprehensive temporal features from tracking data\"\"\"\n        print(\"Extracting temporal features...\")\n        \n        # Get last frame before throw\n        last_frame = tracking_data.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id']) \\\n                                 .groupby(['game_id', 'play_id', 'nfl_id'], as_index=False).last()\n        last_frame = last_frame.rename(columns={'x': 'final_pre_throw_x', 'y': 'final_pre_throw_y'})\n        \n        # Calculate temporal statistics from all frames before throw\n        temporal_stats = tracking_data.groupby(['game_id', 'play_id', 'nfl_id']).agg({\n            'x': ['mean', 'std', 'min', 'max'],\n            'y': ['mean', 'std', 'min', 'max'],\n            's': ['mean', 'std', 'max', 'min'],\n            'a': ['mean', 'std', 'max', 'min'],\n            'dir': lambda x: np.std(np.diff(x)) if len(x) > 1 else 0,\n            'o': lambda x: np.std(np.diff(x)) if len(x) > 1 else 0,\n        }).reset_index()\n        \n        # Flatten column names\n        temporal_stats.columns = ['_'.join(col).strip() if col[1] else col[0] \n                                  for col in temporal_stats.columns.values]\n        temporal_stats = temporal_stats.rename(columns={\n            'dir_<lambda>': 'dir_change_rate',\n            'o_<lambda>': 'orientation_change_rate'\n        })\n        \n        # Get movement patterns from last N frames\n        last_n_frames = 5\n        recent_frames = tracking_data.sort_values(['game_id', 'play_id', 'nfl_id', 'frame_id']) \\\n                                    .groupby(['game_id', 'play_id', 'nfl_id']).tail(last_n_frames)\n        \n        # Calculate trajectory features from recent frames\n        trajectory_features = recent_frames.groupby(['game_id', 'play_id', 'nfl_id']).agg({\n            'x': lambda x: (x.iloc[-1] - x.iloc[0]) if len(x) > 1 else 0,\n            'y': lambda x: (x.iloc[-1] - x.iloc[0]) if len(x) > 1 else 0,\n            's': lambda x: x.diff().mean() if len(x) > 1 else 0,\n        }).reset_index()\n        trajectory_features.columns = ['game_id', 'play_id', 'nfl_id', \n                                      'recent_displacement_x', 'recent_displacement_y', 'acceleration_trend']\n        \n        # Merge temporal features\n        last_frame = last_frame.merge(temporal_stats, on=['game_id', 'play_id', 'nfl_id'], how='left')\n        last_frame = last_frame.merge(trajectory_features, on=['game_id', 'play_id', 'nfl_id'], how='left')\n        \n        # Convert height if available\n        if 'player_height' in last_frame.columns:\n            last_frame['height_inches'] = last_frame['player_height'].apply(self._convert_height_to_inches)\n        \n        return last_frame\n    \n    def _incorporate_target_receiver_data(self, player_data):\n        \"\"\"Add target receiver position data to all players in the same play\"\"\"\n        if 'player_role' not in player_data.columns:\n            print(\"Warning: 'player_role' column not found. Skipping target receiver incorporation.\")\n            player_data['target_receiver_x'] = np.nan\n            player_data['target_receiver_y'] = np.nan\n            return player_data\n        \n        target_receivers = player_data[player_data['player_role'] == \"Targeted Receiver\"][\n            ['game_id', 'play_id', 'final_pre_throw_x', 'final_pre_throw_y']\n        ].rename(columns={\n            'final_pre_throw_x': 'target_receiver_x', \n            'final_pre_throw_y': 'target_receiver_y'\n        })\n        \n        # Remove duplicates if any\n        target_receivers = target_receivers.drop_duplicates(['game_id', 'play_id'])\n        \n        return player_data.merge(target_receivers, on=['game_id', 'play_id'], how='left')\n    \n    def _calculate_advanced_features(self, data_frame, training_mode=False):\n        \"\"\"Create comprehensive feature set with advanced temporal and physics features\"\"\"\n        df = data_frame.copy()\n        \n        print(\"Calculating advanced features...\")\n        \n        # ===== TEMPORAL FEATURES =====\n        if 'frame_id' in df.columns:\n            df['time_seconds'] = df['frame_id'] / 10.0  # 10 FPS\n            df['time_normalized'] = df['frame_id'] / df.groupby(['game_id', 'play_id', 'nfl_id'])['frame_id'].transform('max')\n            \n            # Polynomial time features\n            df['time_squared'] = df['time_seconds'] ** 2\n            df['time_cubed'] = df['time_seconds'] ** 3\n            df['sqrt_time'] = np.sqrt(df['time_seconds'])\n            df['log_time'] = np.log1p(df['time_seconds'])\n            \n            # Fourier features for cyclical patterns\n            df['time_sin'] = np.sin(2 * np.pi * df['time_normalized'])\n            df['time_cos'] = np.cos(2 * np.pi * df['time_normalized'])\n            df['time_sin_2'] = np.sin(4 * np.pi * df['time_normalized'])\n            df['time_cos_2'] = np.cos(4 * np.pi * df['time_normalized'])\n            \n            # Phase-based features\n            df['is_early_play'] = (df['time_normalized'] < 0.33).astype(int)\n            df['is_mid_play'] = ((df['time_normalized'] >= 0.33) & (df['time_normalized'] < 0.67)).astype(int)\n            df['is_late_play'] = (df['time_normalized'] >= 0.67).astype(int)\n        \n        # ===== VELOCITY AND PHYSICS FEATURES =====\n        if all(col in df.columns for col in ['s', 'dir']):\n            direction_radians = np.deg2rad(df['dir'].fillna(0))\n            df['velocity_x'] = df['s'] * np.sin(direction_radians)\n            df['velocity_y'] = df['s'] * np.cos(direction_radians)\n            \n            # Momentum features\n            if 'player_weight' in df.columns:\n                df['momentum_magnitude'] = df['player_weight'] * df['s']\n            \n            # Expected positions based on physics\n            if 'time_seconds' in df.columns:\n                df['expected_x_constant_v'] = df['final_pre_throw_x'] + df['velocity_x'] * df['time_seconds']\n                df['expected_y_constant_v'] = df['final_pre_throw_y'] + df['velocity_y'] * df['time_seconds']\n                \n                if 'a' in df.columns:\n                    df['expected_x_with_accel'] = df['final_pre_throw_x'] + df['velocity_x'] * df['time_seconds'] + \\\n                                                  0.5 * df['a'] * np.sin(direction_radians) * df['time_squared']\n                    df['expected_y_with_accel'] = df['final_pre_throw_y'] + df['velocity_y'] * df['time_seconds'] + \\\n                                                  0.5 * df['a'] * np.cos(direction_radians) * df['time_squared']\n        \n        # ===== MOVEMENT CONSISTENCY FEATURES =====\n        if 's_mean' in df.columns:\n            df['speed_consistency'] = df['s'] / (df['s_mean'] + 0.1)\n            df['speed_deviation'] = np.abs(df['s'] - df['s_mean'])\n            \n        if 'a_mean' in df.columns:\n            df['acceleration_consistency'] = df['a'] / (df['a_mean'] + 0.1)\n            df['acceleration_deviation'] = np.abs(df['a'] - df['a_mean'])\n        \n        # ===== TEMPORAL INTERACTION FEATURES =====\n        if 'time_seconds' in df.columns:\n            df['time_x_speed'] = df['time_seconds'] * df['s']\n            df['time_x_acceleration'] = df['time_seconds'] * df['a']\n            if 'time_squared' in df.columns:\n                df['time_squared_x_speed'] = df['time_squared'] * df['s']\n        \n        # ===== BALL TRAJECTORY FEATURES =====\n        if all(col in df.columns for col in ['ball_land_x', 'ball_land_y', 'final_pre_throw_x', 'final_pre_throw_y']):\n            ball_dx = df['ball_land_x'] - df['final_pre_throw_x']\n            ball_dy = df['ball_land_y'] - df['final_pre_throw_y']\n            df['distance_to_ball_landing'] = np.sqrt(ball_dx**2 + ball_dy**2)\n            df['angle_to_ball_landing'] = np.arctan2(ball_dy, ball_dx)\n            \n            # Ball direction unit vectors\n            df['ball_direction_x'] = ball_dx / (df['distance_to_ball_landing'] + 1e-6)\n            df['ball_direction_y'] = ball_dy / (df['distance_to_ball_landing'] + 1e-6)\n            \n            # Time until ball arrival\n            estimated_ball_speed = 20.0\n            df['estimated_time_to_ball'] = df['distance_to_ball_landing'] / estimated_ball_speed\n            if 'time_seconds' in df.columns:\n                df['time_ratio_to_ball'] = df['time_seconds'] / (df['estimated_time_to_ball'] + 0.1)\n            \n            # Closing speed\n            if 'velocity_x' in df.columns:\n                ball_unit_x = ball_dx / (df['distance_to_ball_landing'] + 1e-6)\n                ball_unit_y = ball_dy / (df['distance_to_ball_landing'] + 1e-6)\n                df['closing_speed'] = df['velocity_x'] * ball_unit_x + df['velocity_y'] * ball_unit_y\n                \n                df['projected_time_to_ball'] = df['distance_to_ball_landing'] / (np.abs(df['closing_speed']) + 0.1)\n                if 'time_seconds' in df.columns:\n                    df['time_urgency'] = df['time_seconds'] / (df['projected_time_to_ball'] + 0.1)\n            \n            # Temporal ball distance features\n            if 'time_seconds' in df.columns:\n                df['distance_to_ball_x_time'] = df['distance_to_ball_landing'] * df['time_seconds']\n                if 'time_squared' in df.columns:\n                    df['distance_to_ball_x_time_squared'] = df['distance_to_ball_landing'] * df['time_squared']\n        \n        # ===== TARGET RECEIVER FEATURES =====\n        if all(col in df.columns for col in ['target_receiver_x', 'target_receiver_y', 'final_pre_throw_x', 'final_pre_throw_y']):\n            target_dx = df['target_receiver_x'] - df['final_pre_throw_x']\n            target_dy = df['target_receiver_y'] - df['final_pre_throw_y']\n            df['distance_to_target'] = np.sqrt(target_dx**2 + target_dy**2)\n            df['angle_to_target'] = np.arctan2(target_dy, target_dx)\n            \n            if 'time_seconds' in df.columns:\n                df['distance_to_target_x_time'] = df['distance_to_target'] * df['time_seconds']\n        \n        # ===== TARGET INDICATOR =====\n        if 'player_role' in df.columns:\n            df['is_target_receiver'] = (df['player_role'] == \"Targeted Receiver\").astype(int)\n        else:\n            df['is_target_receiver'] = 0\n        \n        # ===== FIELD POSITION FEATURES =====\n        if 'final_pre_throw_x' in df.columns:\n            df['normalized_x'] = df['final_pre_throw_x'] / Config.FIELD_X_MAX\n            df['field_region_x'] = pd.cut(df['final_pre_throw_x'], bins=6, labels=False)\n            df['distance_from_endzone'] = np.minimum(df['final_pre_throw_x'], Config.FIELD_X_MAX - df['final_pre_throw_x'])\n        \n        if 'final_pre_throw_y' in df.columns:\n            df['normalized_y'] = df['final_pre_throw_y'] / Config.FIELD_Y_MAX\n            df['field_region_y'] = pd.cut(df['final_pre_throw_y'], bins=4, labels=False)\n            df['distance_from_sideline'] = np.minimum(df['final_pre_throw_y'], Config.FIELD_Y_MAX - df['final_pre_throw_y'])\n        \n        # ===== GAME CONTEXT FEATURES =====\n        if 'absolute_yardline_number' in df.columns:\n            df['yards_to_endzone'] = df['absolute_yardline_number']\n            df['is_redzone'] = (df['absolute_yardline_number'] <= 20).astype(int)\n        \n        # ===== TEAM INDICATOR =====\n        if 'player_side' in df.columns:\n            df['is_offense'] = (df['player_side'] == 'Offense').astype(int)\n            df['is_passer'] = (df['player_role'] == 'Passer').astype(int)\n            df['is_coverage'] = (df['player_role'] == 'Defensive Coverage').astype(int)\n        else:\n            df['is_offense'] = 0\n            df['is_passer'] = 0\n            df['is_coverage'] = 0\n        \n        # ===== PLAYER PHYSICAL ATTRIBUTES =====\n        if all(col in df.columns for col in ['player_weight', 'height_inches']):\n            valid_height = df['height_inches'] > 0\n            df['bmi'] = np.nan\n            df.loc[valid_height, 'bmi'] = (df.loc[valid_height, 'player_weight'] * 0.453592) / (\n                (df.loc[valid_height, 'height_inches'] * 0.0254) ** 2)\n        \n        # ===== MOTION ANALYSIS FEATURES =====\n        if all(col in df.columns for col in ['dir', 'o']):\n            df['speed_orientation_discrepancy'] = np.abs(df['dir'] - df['o'])\n        \n        # ===== INTERACTION FEATURES =====\n        if all(col in df.columns for col in ['s', 'a']):\n            df['speed_times_acceleration'] = df['s'] * df['a']\n        \n        if all(col in df.columns for col in ['distance_to_ball_landing', 's']):\n            df['distance_speed_ratio'] = df['distance_to_ball_landing'] / (df['s'] + 1.0)\n            df['distance_ball_x_speed'] = df['distance_to_ball_landing'] * df['s']\n        \n        # ===== ADVANCED INTERACTION FEATURES =====\n        if 'is_target_receiver' in df.columns and 'time_seconds' in df.columns:\n            df['is_target_x_time'] = df['is_target_receiver'] * df['time_seconds']\n            if 'time_squared' in df.columns:\n                df['is_target_x_time_squared'] = df['is_target_receiver'] * df['time_squared']\n        \n        if 'is_offense' in df.columns:\n            if 'is_early_play' in df.columns:\n                df['is_offense_x_early_play'] = df['is_offense'] * df['is_early_play']\n            if 'is_late_play' in df.columns:\n                df['is_offense_x_late_play'] = df['is_offense'] * df['is_late_play']\n        \n        if 'is_target_receiver' in df.columns and 'is_late_play' in df.columns:\n            df['is_target_x_late_play'] = df['is_target_receiver'] * df['is_late_play']\n        \n        # ===== TRAINING TARGETS =====\n        if training_mode and all(col in df.columns for col in ['x', 'final_pre_throw_x', 'y', 'final_pre_throw_y']):\n            df['displacement_x'] = df['x'] - df['final_pre_throw_x']\n            df['displacement_y'] = df['y'] - df['final_pre_throw_y']\n        \n        return df\n    \n    def _encode_categorical_features(self, data_frame, categorical_columns):\n        \"\"\"Encode categorical variables with label encoding\"\"\"\n        encoded_df = data_frame.copy()\n        \n        for col in categorical_columns:\n            if col in encoded_df.columns:\n                if col not in self.label_encoders:\n                    self.label_encoders[col] = LabelEncoder()\n                    # Handle NaN values\n                    encoded_df[col] = encoded_df[col].fillna('Unknown')\n                    encoded_df[col] = self.label_encoders[col].fit_transform(encoded_df[col])\n                else:\n                    encoded_df[col] = encoded_df[col].fillna('Unknown')\n                    # Handle unseen categories\n                    unique_vals = set(encoded_df[col].unique())\n                    trained_vals = set(self.label_encoders[col].classes_)\n                    if not unique_vals.issubset(trained_vals):\n                        # For unseen categories, use 'Unknown'\n                        encoded_df[col] = encoded_df[col].apply(\n                            lambda x: x if x in trained_vals else 'Unknown'\n                        )\n                    encoded_df[col] = self.label_encoders[col].transform(encoded_df[col])\n            else:\n                print(f\"Warning: Categorical column '{col}' not found in data. Skipping.\")\n                # Add as constant if missing\n                encoded_df[col] = 0\n        \n        return encoded_df\n    \n    def prepare_features(self, input_data, output_data, training_mode=False):\n        \"\"\"Complete feature engineering pipeline with temporal features\"\"\"\n        print(\"Extracting temporal features...\")\n        temporal_features = self._extract_temporal_features(input_data)\n        print(\"Incorporating target receiver data...\")\n        temporal_features = self._incorporate_target_receiver_data(temporal_features)\n        \n        # Identify available columns for merging\n        available_columns = temporal_features.columns.tolist()\n        merge_columns = ['game_id', 'play_id', 'nfl_id']\n        \n        # Add other columns if they exist\n        optional_columns = [\n            'final_pre_throw_x', 'final_pre_throw_y', 's', 'a', 'o', 'dir',\n            'player_role', 'player_side', 'num_frames_output', 'ball_land_x', \n            'ball_land_y', 'target_receiver_x', 'target_receiver_y',\n            'play_direction', 'absolute_yardline_number', 'height_inches', 'player_weight',\n            # Temporal features\n            'x_mean', 'x_std', 'x_min', 'x_max',\n            'y_mean', 'y_std', 'y_min', 'y_max',\n            's_mean', 's_std', 's_max', 's_min',\n            'a_mean', 'a_std', 'a_max', 'a_min',\n            'dir_change_rate', 'orientation_change_rate',\n            'recent_displacement_x', 'recent_displacement_y', 'acceleration_trend'\n        ]\n        \n        for col in optional_columns:\n            if col in available_columns:\n                merge_columns.append(col)\n        \n        print(f\"Merging with columns: {len(merge_columns)} columns\")\n        \n        # Merge with output data\n        merged_data = output_data.merge(\n            temporal_features[merge_columns],\n            on=['game_id', 'play_id', 'nfl_id'],\n            how='left'\n        )\n        \n        print(\"Calculating advanced features...\")\n        return self._calculate_advanced_features(merged_data, training_mode=training_mode)\n    \n    def train_models(self):\n        \"\"\"Train ensemble models with cross-validation and neural networks\"\"\"\n        # Print GPU information\n        Config.print_gpu_info()\n        \n        # Load data\n        print(\"Loading datasets...\")\n        train_input, train_output, test_input, test_template = self.load_and_combine_datasets()\n        \n        # Prepare features\n        print(\"Preparing training features...\")\n        self.train_data = self.prepare_features(train_input, train_output, training_mode=True)\n        \n        print(\"Preparing test features...\")\n        self.test_data = self.prepare_features(test_input, test_template, training_mode=False)\n        \n        # Define feature sets based on available columns\n        available_columns = self.train_data.columns.tolist()\n        print(f\"Available columns in training data: {len(available_columns)}\")\n        \n        # Define comprehensive feature list\n        potential_numerical_features = [\n            # Position and movement\n            'final_pre_throw_x', 'final_pre_throw_y', 's', 'a', 'o', 'dir',\n            \n            # Time features\n            'time_seconds', 'time_normalized', 'time_squared', 'time_cubed', \n            'sqrt_time', 'log_time', 'time_sin', 'time_cos', 'time_sin_2', 'time_cos_2',\n            'is_early_play', 'is_mid_play', 'is_late_play',\n            \n            # Historical statistics\n            'x_mean', 'x_std', 'x_min', 'x_max',\n            'y_mean', 'y_std', 'y_min', 'y_max',\n            's_mean', 's_std', 's_max', 's_min',\n            'a_mean', 'a_std', 'a_max', 'a_min',\n            'dir_change_rate', 'orientation_change_rate',\n            'recent_displacement_x', 'recent_displacement_y', 'acceleration_trend',\n            \n            # Movement consistency\n            'speed_consistency', 'speed_deviation',\n            'acceleration_consistency', 'acceleration_deviation',\n            \n            # Velocity and physics\n            'velocity_x', 'velocity_y', 'momentum_magnitude',\n            'expected_x_constant_v', 'expected_y_constant_v',\n            'expected_x_with_accel', 'expected_y_with_accel',\n            \n            # Ball features\n            'distance_to_ball_landing', 'angle_to_ball_landing', 'closing_speed',\n            'ball_direction_x', 'ball_direction_y',\n            'estimated_time_to_ball', 'time_ratio_to_ball',\n            'projected_time_to_ball', 'time_urgency',\n            'distance_to_ball_x_time', 'distance_to_ball_x_time_squared',\n            \n            # Target features\n            'distance_to_target', 'is_target_receiver', 'angle_to_target',\n            'distance_to_target_x_time', 'is_target_x_time_squared',\n            \n            # Field position\n            'normalized_x', 'normalized_y', 'field_region_x', 'field_region_y',\n            'distance_from_sideline', 'distance_from_endzone',\n            \n            # Game context\n            'yards_to_endzone', 'is_offense', 'is_passer', 'is_coverage', 'is_redzone',\n            \n            # Player attributes\n            'height_inches', 'player_weight', 'bmi',\n            \n            # Motion analysis\n            'speed_orientation_discrepancy', 'motion_consistency',\n            'proximity_to_ball_ratio', 'lateral_position_importance', 'downfield_progress',\n            \n            # Interactions\n            'speed_times_acceleration', 'distance_speed_ratio', 'distance_ball_x_speed',\n            'time_x_speed', 'time_x_acceleration', 'time_squared_x_speed',\n            'is_target_x_time', 'is_offense_x_early_play', 'is_offense_x_late_play', 'is_target_x_late_play'\n        ]\n        \n        potential_categorical_features = ['player_role', 'player_side', 'play_direction']\n        \n        # Select only features that exist in the data\n        self.numerical_features = [f for f in potential_numerical_features if f in available_columns]\n        self.categorical_features = [f for f in potential_categorical_features if f in available_columns]\n        \n        print(f\"Using {len(self.numerical_features)} numerical features\")\n        print(f\"Using {len(self.categorical_features)} categorical features\")\n        \n        # Check if we have target variables for training\n        if not all(col in self.train_data.columns for col in ['displacement_x', 'displacement_y']):\n            raise KeyError(\"Target variables (displacement_x, displacement_y) not found in training data\")\n        \n        # Prepare training data\n        print(\"Preparing training matrix...\")\n        X_train = self.train_data[self.numerical_features + self.categorical_features].copy()\n        X_train = self._encode_categorical_features(X_train, self.categorical_features)\n        \n        # Handle missing values\n        X_train = X_train.fillna(0)\n        \n        # Scale numerical features\n        self.scalers['numerical'] = StandardScaler()\n        X_train[self.numerical_features] = self.scalers['numerical'].fit_transform(\n            X_train[self.numerical_features]\n        )\n        \n        y_dx = self.train_data['displacement_x'].values\n        y_dy = self.train_data['displacement_y'].values\n        \n        print(f\"Training data shape: {X_train.shape}\")\n        \n        # Train with cross-validation\n        self._train_with_cv(X_train, y_dx, y_dy)\n        \n        print(\"Model training completed!\")\n        return self\n    \n    def _train_with_cv(self, X_train, y_dx, y_dy):\n        \"\"\"Train models with cross-validation\"\"\"\n        print(\"Training models with cross-validation...\")\n        \n        # Cross-validation setup\n        groups = self.train_data['game_id'].values\n        gkf = GroupKFold(n_splits=Config.N_FOLDS)\n        \n        # Initialize model lists\n        self.models_dx = {'xgb': [], 'lgb': [], 'cat': []}\n        self.models_dy = {'xgb': [], 'lgb': [], 'cat': []}\n        self.nn_models_dx = []\n        self.nn_models_dy = []\n        \n        for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train, groups=groups)):\n            print(f\"  Fold {fold + 1}/{Config.N_FOLDS}\")\n            \n            X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n            y_train_dx, y_val_dx = y_dx[train_idx], y_dx[val_idx]\n            y_train_dy, y_val_dy = y_dy[train_idx], y_dy[val_idx]\n            \n            # XGBoost with GPU support\n            xgb_params = {\n                'n_estimators': 2000,\n                'learning_rate': 0.05,\n                'max_depth': 8,\n                'subsample': 0.8,\n                'colsample_bytree': 0.8,\n                'random_state': self.seed + fold,\n                'verbosity': 0,\n                'objective': 'reg:squarederror',\n            }\n            \n            # Add GPU support if available\n            if Config.USE_GPU and torch.cuda.is_available():\n                xgb_params.update({\n                    'tree_method': 'gpu_hist',\n                    'predictor': 'gpu_predictor',\n                    'gpu_id': 0\n                })\n                print(f\"    Training XGBoost on GPU for fold {fold + 1}\")\n            else:\n                xgb_params['tree_method'] = 'hist'\n                print(f\"    Training XGBoost on CPU for fold {fold + 1}\")\n            \n            xgb_dx = XGBRegressor(**xgb_params)\n            xgb_dx.fit(X_train_fold, y_train_dx)\n            self.models_dx['xgb'].append(xgb_dx)\n            \n            xgb_dy = XGBRegressor(**xgb_params)\n            xgb_dy.fit(X_train_fold, y_train_dy)\n            self.models_dy['xgb'].append(xgb_dy)\n            \n            # LightGBM with GPU support\n            lgb_params = {\n                'n_estimators': 2000,\n                'learning_rate': 0.05,\n                'max_depth': 8,\n                'num_leaves': 100,\n                'subsample': 0.8,\n                'colsample_bytree': 0.8,\n                'random_state': self.seed + fold,\n                'verbosity': -1,\n                'objective': 'regression',\n            }\n            \n            # Add GPU support if available\n            if Config.USE_GPU and torch.cuda.is_available():\n                lgb_params.update({\n                    'device': 'gpu',\n                    'gpu_platform_id': 0,\n                    'gpu_device_id': 0\n                })\n                print(f\"    Training LightGBM on GPU for fold {fold + 1}\")\n            else:\n                print(f\"    Training LightGBM on CPU for fold {fold + 1}\")\n            \n            lgb_dx = LGBMRegressor(**lgb_params)\n            lgb_dx.fit(X_train_fold, y_train_dx)\n            self.models_dx['lgb'].append(lgb_dx)\n            \n            lgb_dy = LGBMRegressor(**lgb_params)\n            lgb_dy.fit(X_train_fold, y_train_dy)\n            self.models_dy['lgb'].append(lgb_dy)\n            \n            # CatBoost with GPU support\n            cat_params = {\n                'iterations': 2000,\n                'learning_rate': 0.05,\n                'depth': 8,\n                'random_seed': self.seed + fold,\n                'verbose': False,\n                'loss_function': 'RMSE',\n                'eval_metric': 'RMSE',\n            }\n            \n            # Add GPU support if available\n            if Config.USE_GPU and torch.cuda.is_available():\n                cat_params.update({\n                    'task_type': 'GPU',\n                    'devices': '0'\n                })\n                print(f\"    Training CatBoost on GPU for fold {fold + 1}\")\n            else:\n                print(f\"    Training CatBoost on CPU for fold {fold + 1}\")\n            \n            cat_dx = CatBoostRegressor(**cat_params)\n            cat_dx.fit(X_train_fold, y_train_dx)\n            self.models_dx['cat'].append(cat_dx)\n            \n            cat_dy = CatBoostRegressor(**cat_params)\n            cat_dy.fit(X_train_fold, y_train_dy)\n            self.models_dy['cat'].append(cat_dy)\n            \n            # Neural Network\n            nn_dx = self._train_neural_network(X_train_fold.values, y_train_dx, X_val_fold.values, y_val_dx, self.seed + fold)\n            self.nn_models_dx.append(nn_dx)\n            \n            nn_dy = self._train_neural_network(X_train_fold.values, y_train_dy, X_val_fold.values, y_val_dy, self.seed + fold + 100)\n            self.nn_models_dy.append(nn_dy)\n            \n            # Clean up GPU memory after each fold\n            Config.cleanup_gpu_memory()\n    \n    def _train_neural_network(self, X_train, y_train, X_val, y_val, seed=42):\n        \"\"\"Train a neural network model with GPU support\"\"\"\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n        \n        device = torch.device(Config.GPU_DEVICE)\n        print(f\"    Training Neural Network on {device} for seed {seed}\")\n        \n        # Create datasets\n        train_dataset = TensorDataset(\n            torch.FloatTensor(X_train), \n            torch.FloatTensor(y_train.reshape(-1, 1))\n        )\n        val_dataset = TensorDataset(\n            torch.FloatTensor(X_val), \n            torch.FloatTensor(y_val.reshape(-1, 1))\n        )\n        \n        train_loader = DataLoader(train_dataset, batch_size=Config.NN_BATCH_SIZE, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=Config.NN_BATCH_SIZE)\n        \n        # Create model\n        model = SimpleNN(X_train.shape[1]).to(device)\n        \n        # Training setup\n        criterion = nn.MSELoss()\n        optimizer = torch.optim.Adam(model.parameters(), lr=Config.NN_LEARNING_RATE)\n        \n        best_val_loss = float('inf')\n        best_model_state = model.state_dict()\n        patience_counter = 0\n        \n        for epoch in range(Config.NN_EPOCHS):\n            # Training\n            model.train()\n            train_losses = []\n            \n            for batch_X, batch_y in train_loader:\n                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(batch_X)\n                loss = criterion(outputs, batch_y)\n                loss.backward()\n                optimizer.step()\n                \n                train_losses.append(loss.item())\n            \n            # Validation\n            model.eval()\n            val_losses = []\n            \n            with torch.no_grad():\n                for batch_X, batch_y in val_loader:\n                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                    outputs = model(batch_X)\n                    loss = criterion(outputs, batch_y)\n                    val_losses.append(loss.item())\n            \n            avg_val_loss = np.mean(val_losses)\n            \n            # Early stopping\n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                best_model_state = model.state_dict()\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= 10:\n                    break\n        \n        # Load best model\n        model.load_state_dict(best_model_state)\n        \n        return model\n    \n    def generate_predictions(self):\n        \"\"\"Generate ensemble predictions for test data\"\"\"\n        print(\"Preparing test features...\")\n        X_test = self.test_data[self.numerical_features + self.categorical_features].copy()\n        X_test = self._encode_categorical_features(X_test, self.categorical_features)\n        X_test = X_test.fillna(0)\n        \n        # Scale numerical features\n        X_test[self.numerical_features] = self.scalers['numerical'].transform(\n            X_test[self.numerical_features]\n        )\n        \n        # Generate ensemble predictions\n        print(\"Generating predictions...\")\n        pred_dx = self._ensemble_prediction(X_test.values, self.models_dx, self.nn_models_dx)\n        pred_dy = self._ensemble_prediction(X_test.values, self.models_dy, self.nn_models_dy)\n        \n        # Calculate final positions\n        self.test_data['predicted_x'] = self.test_data['final_pre_throw_x'] + pred_dx\n        self.test_data['predicted_y'] = self.test_data['final_pre_throw_y'] + pred_dy\n        \n        # Apply physics constraints\n        self.test_data = self._apply_constraints(self.test_data)\n        \n        # Smooth trajectories\n        self.test_data = self._smooth_trajectories(self.test_data)\n        \n        return self.test_data\n    \n    def _ensemble_prediction(self, X, tree_models, nn_models):\n        \"\"\"Generate weighted ensemble predictions from tree models and neural networks\"\"\"\n        predictions = []\n        \n        # Tree model predictions\n        weights = {'xgb': 0.3, 'lgb': 0.3, 'cat': 0.2}\n        \n        for model_name, models in tree_models.items():\n            if model_name in weights:\n                fold_preds = []\n                for model in models:\n                    fold_preds.append(model.predict(X))\n                avg_pred = np.mean(fold_preds, axis=0)\n                predictions.append(avg_pred * weights[model_name])\n        \n        # Neural network predictions\n        device = torch.device(Config.GPU_DEVICE)\n        X_tensor = torch.FloatTensor(X).to(device)\n        \n        nn_preds = []\n        for model in nn_models:\n            model.eval()\n            with torch.no_grad():\n                pred = model(X_tensor).cpu().numpy().squeeze()\n            nn_preds.append(pred)\n        \n        nn_avg_pred = np.mean(nn_preds, axis=0)\n        predictions.append(nn_avg_pred * 0.2)  # 20% weight for NN\n        \n        return np.sum(predictions, axis=0)\n    \n    def _apply_constraints(self, test_data):\n        \"\"\"Apply physics constraints to predictions\"\"\"\n        print(\"Applying physics constraints...\")\n        \n        dx = test_data['predicted_x'] - test_data['final_pre_throw_x']\n        dy = test_data['predicted_y'] - test_data['final_pre_throw_y']\n        displacement = np.sqrt(dx**2 + dy**2)\n        \n        if 'time_seconds' in test_data.columns:\n            max_displacement = Config.MAX_SPEED * test_data['time_seconds']\n            \n            # Scale down impossible movements\n            mask = displacement > max_displacement\n            if np.any(mask):\n                scale = max_displacement[mask] / (displacement[mask] + 1e-6)\n                dx[mask] *= scale\n                dy[mask] *= scale\n                test_data.loc[mask, 'predicted_x'] = test_data.loc[mask, 'final_pre_throw_x'] + dx[mask]\n                test_data.loc[mask, 'predicted_y'] = test_data.loc[mask, 'final_pre_throw_y'] + dy[mask]\n        \n        # Clip to field boundaries\n        test_data['predicted_x'] = test_data['predicted_x'].clip(Config.FIELD_X_MIN, Config.FIELD_X_MAX)\n        test_data['predicted_y'] = test_data['predicted_y'].clip(Config.FIELD_Y_MIN, Config.FIELD_Y_MAX)\n        \n        return test_data\n    \n    def _smooth_trajectories(self, test_data):\n        \"\"\"Smooth trajectories using Gaussian filtering\"\"\"\n        print(\"Smoothing trajectories...\")\n        \n        for (game_id, play_id, nfl_id), group in test_data.groupby(['game_id', 'play_id', 'nfl_id']):\n            if len(group) > 3:\n                idx = group.index\n                test_data.loc[idx, 'predicted_x'] = gaussian_filter1d(group['predicted_x'].values, sigma=0.5)\n                test_data.loc[idx, 'predicted_y'] = gaussian_filter1d(group['predicted_y'].values, sigma=0.5)\n        \n        return test_data\n    \n    def create_submission_file(self, output_path=\"submission.csv\"):\n        \"\"\"Create submission file in required format\"\"\"\n        # Create ID column\n        self.test_data['unique_id'] = (\n            self.test_data['game_id'].astype(str) + \"_\" +\n            self.test_data['play_id'].astype(str) + \"_\" +\n            self.test_data['nfl_id'].astype(str) + \"_\" +\n            self.test_data['frame_id'].astype(str)\n        )\n        \n        submission_df = self.test_data[['unique_id', 'predicted_x', 'predicted_y']].rename(\n            columns={'predicted_x': 'x', 'predicted_y': 'y', 'unique_id': 'id'}\n        )\n        \n        submission_df.to_csv(output_path, index=False)\n        print(f\"Submission file saved to {output_path}\")\n        print(f\"Submission shape: {submission_df.shape}\")\n        return submission_df\n\n# ================================================================================\n# NEURAL NETWORK MODEL\n# ================================================================================\n\nclass SimpleNN(nn.Module):\n    \"\"\"Simple neural network for regression\"\"\"\n    \n    def __init__(self, input_dim):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n        \n    def forward(self, x):\n        return self.layers(x)\n\n# ================================================================================\n# MAIN EXECUTION\n# ================================================================================\n\nif __name__ == \"__main__\":\n    try:\n        # Check GPU requirements\n        print(\"üîç Checking GPU requirements...\")\n        check_gpu_requirements()\n        \n        # Print initial GPU information\n        Config.print_gpu_info()\n        \n        # Initialize enhanced predictor\n        predictor = EnhancedNFLPlayerMovementPredictor(\n            data_dir=\"/kaggle/input/nfl-big-data-bowl-2026-prediction/\",\n            seed=42\n        )\n        \n        # Train models\n        print(\"\\nüöÄ Training enhanced models with GPU acceleration...\")\n        predictor.train_models()\n        \n        # Generate predictions\n        print(\"\\nüìä Generating predictions...\")\n        predictions = predictor.generate_predictions()\n        \n        # Create submission\n        print(\"\\nüíæ Creating submission file...\")\n        submission = predictor.create_submission_file(\"/kaggle/working/submission.csv\")\n        \n        print(\"\\n‚úÖ Enhanced pipeline completed successfully!\")\n        print(f\"üìà Final submission shape: {submission.shape}\")\n        print(\"\\nFirst 5 predictions:\")\n        print(submission.head())\n        \n        # Final GPU memory cleanup\n        Config.cleanup_gpu_memory()\n        \n    except Exception as e:\n        print(f\"‚ùå Error occurred: {e}\")\n        import traceback\n        traceback.print_exc()\n        \n        # Cleanup on error\n        Config.cleanup_gpu_memory()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:29:07.216331Z","iopub.execute_input":"2025-09-30T16:29:07.216563Z","iopub.status.idle":"2025-09-30T17:14:51.381382Z","shell.execute_reply.started":"2025-09-30T16:29:07.216544Z","shell.execute_reply":"2025-09-30T17:14:51.380566Z"}},"outputs":[{"name":"stdout","text":"üîç Checking GPU requirements...\n‚úÖ CUDA is available\n‚úÖ XGBoost GPU support available\n‚úÖ LightGBM GPU support available\n‚úÖ CatBoost GPU support available\n============================================================\nGPU CONFIGURATION\n============================================================\nCUDA Available: True\nGPU Device: cuda\nGPU Count: 2\nGPU 0: Tesla T4 (14.7 GB)\nGPU 1: Tesla T4 (14.7 GB)\n============================================================\n\nüöÄ Training enhanced models with GPU acceleration...\n============================================================\nGPU CONFIGURATION\n============================================================\nCUDA Available: True\nGPU Device: cuda\nGPU Count: 2\nGPU 0: Tesla T4 (14.7 GB)\nGPU 1: Tesla T4 (14.7 GB)\n============================================================\nLoading datasets...\nLoading datasets...\nFound 17 weeks of training data\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading files:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3b73cfce694dbcb7d59aba93738590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading files:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19a578f4684a425a995a8c13cd2b87cd"}},"metadata":{}},{"name":"stdout","text":"Loaded 4,625,662 input records, 533,254 output records\nPreparing training features...\nExtracting temporal features...\nExtracting temporal features...\nIncorporating target receiver data...\nMerging with columns: 41 columns\nCalculating advanced features...\nCalculating advanced features...\nPreparing test features...\nExtracting temporal features...\nExtracting temporal features...\nIncorporating target receiver data...\nMerging with columns: 41 columns\nCalculating advanced features...\nCalculating advanced features...\nAvailable columns in training data: 109\nUsing 92 numerical features\nUsing 3 categorical features\nPreparing training matrix...\nTraining data shape: (533254, 95)\nTraining models with cross-validation...\n  Fold 1/5\n    Training XGBoost on GPU for fold 1\n    Training LightGBM on GPU for fold 1\n    Training CatBoost on GPU for fold 1\n    Training Neural Network on cuda for seed 42\n    Training Neural Network on cuda for seed 142\n  Fold 2/5\n    Training XGBoost on GPU for fold 2\n    Training LightGBM on GPU for fold 2\n    Training CatBoost on GPU for fold 2\n    Training Neural Network on cuda for seed 43\n    Training Neural Network on cuda for seed 143\n  Fold 3/5\n    Training XGBoost on GPU for fold 3\n    Training LightGBM on GPU for fold 3\n    Training CatBoost on GPU for fold 3\n    Training Neural Network on cuda for seed 44\n    Training Neural Network on cuda for seed 144\n  Fold 4/5\n    Training XGBoost on GPU for fold 4\n    Training LightGBM on GPU for fold 4\n    Training CatBoost on GPU for fold 4\n    Training Neural Network on cuda for seed 45\n    Training Neural Network on cuda for seed 145\n  Fold 5/5\n    Training XGBoost on GPU for fold 5\n    Training LightGBM on GPU for fold 5\n    Training CatBoost on GPU for fold 5\n    Training Neural Network on cuda for seed 46\n    Training Neural Network on cuda for seed 146\nModel training completed!\n\nüìä Generating predictions...\nPreparing test features...\nGenerating predictions...\nApplying physics constraints...\nSmoothing trajectories...\n\nüíæ Creating submission file...\nSubmission file saved to /kaggle/working/submission.csv\nSubmission shape: (5837, 3)\n\n‚úÖ Enhanced pipeline completed successfully!\nüìà Final submission shape: (5837, 3)\n\nFirst 5 predictions:\n                      id          x          y\n0  2024120805_74_54586_1  88.345283  34.334058\n1  2024120805_74_54586_2  88.620777  34.343538\n2  2024120805_74_54586_3  88.944078  34.383381\n3  2024120805_74_54586_4  89.302663  34.513068\n4  2024120805_74_54586_5  89.659643  34.697472\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print (submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:17:48.112292Z","iopub.execute_input":"2025-09-30T17:17:48.112564Z","iopub.status.idle":"2025-09-30T17:17:48.119334Z","shell.execute_reply.started":"2025-09-30T17:17:48.112545Z","shell.execute_reply":"2025-09-30T17:17:48.118590Z"}},"outputs":[{"name":"stdout","text":"                            id           x          y\n0        2024120805_74_54586_1   88.345283  34.334058\n1        2024120805_74_54586_2   88.620777  34.343538\n2        2024120805_74_54586_3   88.944078  34.383381\n3        2024120805_74_54586_4   89.302663  34.513068\n4        2024120805_74_54586_5   89.659643  34.697472\n...                        ...         ...        ...\n5832  2025010515_3902_55112_26  100.030285  26.964092\n5833  2025010515_3902_55112_27  100.576586  27.264027\n5834  2025010515_3902_55112_28  101.251288  27.514923\n5835  2025010515_3902_55112_29  102.085334  27.736215\n5836  2025010515_3902_55112_30  102.653286  27.844635\n\n[5837 rows x 3 columns]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:19:07.399288Z","iopub.execute_input":"2025-09-30T17:19:07.399972Z","iopub.status.idle":"2025-09-30T17:19:07.427768Z","shell.execute_reply.started":"2025-09-30T17:19:07.399944Z","shell.execute_reply":"2025-09-30T17:19:07.427017Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
